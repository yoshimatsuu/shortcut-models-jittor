=== Parameters ===
Model Params:	32.79 [million]
=== Dataset ===
Batch size: 128
Train data:
Batches:	469

[ Started training ]

Step 1: (loss: 1.110600471496582, loss_fm: 1.110600471496582, loss_sc: 0.0, lr: 1.9989000574955988e-07)
	->->-> Sampled.
Step 101: (loss: 0.9772930145263672, loss_fm: 0.9772928357124329, loss_sc: 1.5777590078869252e-07, lr: 9.653027918322868e-06)
Step 201: (loss: 0.35445868968963623, loss_fm: 0.3457218110561371, loss_sc: 0.0087368693202734, lr: 1.811758906252399e-05)
Step 301: (loss: 0.22243094444274902, loss_fm: 0.21743269264698029, loss_sc: 0.004998259246349335, lr: 2.569354313579967e-05)
Step 401: (loss: 0.1875413954257965, loss_fm: 0.1843384951353073, loss_sc: 0.003202902153134346, lr: 3.2470740210850316e-05)
Step 501: (loss: 0.19012148678302765, loss_fm: 0.18783394992351532, loss_sc: 0.0022875338327139616, lr: 3.8529940801780945e-05)
Step 601: (loss: 0.18487395346164703, loss_fm: 0.1828240305185318, loss_sc: 0.002049919916316867, lr: 4.394374030763749e-05)
Step 701: (loss: 0.1893468201160431, loss_fm: 0.18824197351932526, loss_sc: 0.0011048413580283523, lr: 4.8777398761348056e-05)
Step 801: (loss: 0.18630118668079376, loss_fm: 0.18532505631446838, loss_sc: 0.000976131297647953, lr: 5.3089585669143424e-05)
Step 901: (loss: 0.1727016121149063, loss_fm: 0.17155182361602783, loss_sc: 0.001149783143773675, lr: 5.693304870369694e-05)
Step 1001: (loss: 0.19322249293327332, loss_fm: 0.19261355698108673, loss_sc: 0.0006089386297389865, lr: 6.0355214100463975e-05)
Step 1101: (loss: 0.16750280559062958, loss_fm: 0.16657330095767975, loss_sc: 0.0009295089403167367, lr: 6.339872578940753e-05)
Step 1201: (loss: 0.15245649218559265, loss_fm: 0.15159745514392853, loss_sc: 0.0008590375073254108, lr: 6.61019295631313e-05)
Step 1301: (loss: 0.1567694991827011, loss_fm: 0.1556130051612854, loss_sc: 0.0011564969317987561, lr: 6.849930792819681e-05)
Step 1401: (loss: 0.15059936046600342, loss_fm: 0.14972008764743805, loss_sc: 0.0008792758453637362, lr: 7.062187070086742e-05)
Step 1501: (loss: 0.15356941521167755, loss_fm: 0.15261210501194, loss_sc: 0.000957306707277894, lr: 7.24975058843852e-05)
Step 1601: (loss: 0.13499486446380615, loss_fm: 0.13368313014507294, loss_sc: 0.001311732456088066, lr: 7.415129489561982e-05)
Step 1701: (loss: 0.12307243794202805, loss_fm: 0.1224467009305954, loss_sc: 0.0006257342174649239, lr: 7.560579578871447e-05)
Step 1801: (loss: 0.1335187554359436, loss_fm: 0.1326296031475067, loss_sc: 0.0008891525212675333, lr: 7.688129774699725e-05)
Step 1901: (loss: 0.13207679986953735, loss_fm: 0.13081896305084229, loss_sc: 0.0012578410096466541, lr: 7.799604977729449e-05)
Step 2001: (loss: 0.12891647219657898, loss_fm: 0.12757167220115662, loss_sc: 0.0013448053505271673, lr: 7.896646623873741e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 2101: (loss: 0.1392010748386383, loss_fm: 0.13827303051948547, loss_sc: 0.000928047054912895, lr: 7.980731156749946e-05)
Step 2201: (loss: 0.13099320232868195, loss_fm: 0.1298454999923706, loss_sc: 0.0011476973304525018, lr: 8.053186631633982e-05)
Step 2301: (loss: 0.11812188476324081, loss_fm: 0.11566062271595001, loss_sc: 0.002461264841258526, lr: 8.115207641041022e-05)
Step 2401: (loss: 0.12136279791593552, loss_fm: 0.11822563409805298, loss_sc: 0.0031371628865599632, lr: 8.16786873258721e-05)
Step 2501: (loss: 0.10918094962835312, loss_fm: 0.10824602097272873, loss_sc: 0.0009349294705316424, lr: 8.212136472311416e-05)
Step 2601: (loss: 0.1176236942410469, loss_fm: 0.1141427755355835, loss_sc: 0.0034809212666004896, lr: 8.248880290965216e-05)
Step 2701: (loss: 0.11895037442445755, loss_fm: 0.11612654477357864, loss_sc: 0.0028238326776772738, lr: 8.2788822367249e-05)
Step 2801: (loss: 0.11264578253030777, loss_fm: 0.10976145416498184, loss_sc: 0.002884326735511422, lr: 8.302845745173087e-05)
Step 2901: (loss: 0.11924723535776138, loss_fm: 0.11745382100343704, loss_sc: 0.0017934116767719388, lr: 8.321403526088691e-05)
Step 3001: (loss: 0.10915043205022812, loss_fm: 0.10656138509511948, loss_sc: 0.0025890448596328497, lr: 8.335124656438011e-05)
Step 3101: (loss: 0.10500634461641312, loss_fm: 0.10388047993183136, loss_sc: 0.0011258679442107677, lr: 8.344520959855426e-05)
Step 3201: (loss: 0.0973394587635994, loss_fm: 0.09585390985012054, loss_sc: 0.0014855513582006097, lr: 8.350052744732355e-05)
Step 3301: (loss: 0.10438766330480576, loss_fm: 0.10247309505939484, loss_sc: 0.0019145708065479994, lr: 8.352133965700333e-05)
Step 3401: (loss: 0.112443707883358, loss_fm: 0.1105901300907135, loss_sc: 0.0018535807030275464, lr: 8.351136866712316e-05)
Step 3501: (loss: 0.08900613337755203, loss_fm: 0.08641483634710312, loss_sc: 0.0025912970304489136, lr: 8.347396158017726e-05)
Step 3601: (loss: 0.09617892652750015, loss_fm: 0.09470898658037186, loss_sc: 0.0014699391322210431, lr: 8.341212774022074e-05)
Step 3701: (loss: 0.10001184046268463, loss_fm: 0.0979173481464386, loss_sc: 0.002094489987939596, lr: 8.332857254258971e-05)
Step 3801: (loss: 0.1061432883143425, loss_fm: 0.10097885876893997, loss_sc: 0.0051644290797412395, lr: 8.322572785425181e-05)
Step 3901: (loss: 0.09731225669384003, loss_fm: 0.09595128148794174, loss_sc: 0.0013609735760837793, lr: 8.310577938588203e-05)
Step 4001: (loss: 0.10535106807947159, loss_fm: 0.10253839939832687, loss_sc: 0.002812671707943082, lr: 8.297069132225876e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 4101: (loss: 0.09513572603464127, loss_fm: 0.09306340664625168, loss_sc: 0.002072317758575082, lr: 8.282222848658592e-05)
Step 4201: (loss: 0.10583556443452835, loss_fm: 0.10315964370965958, loss_sc: 0.0026759181637316942, lr: 8.266197628650813e-05)
Step 4301: (loss: 0.09512534737586975, loss_fm: 0.09432383626699448, loss_sc: 0.0008015082566998899, lr: 8.249135866457625e-05)
Step 4401: (loss: 0.09700144827365875, loss_fm: 0.09511426091194153, loss_sc: 0.0018871837528422475, lr: 8.231165425344873e-05)
Step 4501: (loss: 0.0996418371796608, loss_fm: 0.09812223166227341, loss_sc: 0.0015196085441857576, lr: 8.212401091592259e-05)
Step 4601: (loss: 0.10732425004243851, loss_fm: 0.1046275869011879, loss_sc: 0.0026966617442667484, lr: 8.192945883174264e-05)
Step 4701: (loss: 0.09547079354524612, loss_fm: 0.09374503791332245, loss_sc: 0.0017257591243833303, lr: 8.172892227683033e-05)
Step 4801: (loss: 0.09879457950592041, loss_fm: 0.09796269983053207, loss_sc: 0.000831883167847991, lr: 8.152323022591701e-05)
Step 4901: (loss: 0.09619332104921341, loss_fm: 0.0943293571472168, loss_sc: 0.0018639671616256237, lr: 8.131312589639183e-05)
Step 5001: (loss: 0.08426256477832794, loss_fm: 0.08363546431064606, loss_sc: 0.0006271005840972066, lr: 8.109927533933257e-05)
Step 5101: (loss: 0.09987813979387283, loss_fm: 0.09541613608598709, loss_sc: 0.004462003242224455, lr: 8.088227517304103e-05)
Step 5201: (loss: 0.09736718982458115, loss_fm: 0.0941198542714119, loss_sc: 0.0032473343890160322, lr: 8.066265954483297e-05)
Step 5301: (loss: 0.09837635606527328, loss_fm: 0.09549760818481445, loss_sc: 0.002878751140087843, lr: 8.044090639822681e-05)
Step 5401: (loss: 0.08435627073049545, loss_fm: 0.07919670641422272, loss_sc: 0.005159564781934023, lr: 8.021744311493704e-05)
Step 5501: (loss: 0.0910903811454773, loss_fm: 0.08935651183128357, loss_sc: 0.001733866985887289, lr: 7.999265159411905e-05)
Step 5601: (loss: 0.08631696552038193, loss_fm: 0.08356931060552597, loss_sc: 0.0027476560790091753, lr: 7.976687282505535e-05)
Step 5701: (loss: 0.09071145206689835, loss_fm: 0.08801593631505966, loss_sc: 0.002695514354854822, lr: 7.954041100384368e-05)
Step 5801: (loss: 0.08963054418563843, loss_fm: 0.08700556308031082, loss_sc: 0.0026249836664646864, lr: 7.931353723958662e-05)
Step 5901: (loss: 0.0929533839225769, loss_fm: 0.08955115079879761, loss_sc: 0.0034022312611341476, lr: 7.908649289102829e-05)
Step 6001: (loss: 0.08929530531167984, loss_fm: 0.08581274747848511, loss_sc: 0.0034825564362108707, lr: 7.8859492570489e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 6101: (loss: 0.08590193092823029, loss_fm: 0.0847432091832161, loss_sc: 0.0011587211629375815, lr: 7.863272684826285e-05)
Step 6201: (loss: 0.09031794965267181, loss_fm: 0.08892618119716644, loss_sc: 0.0013917674077674747, lr: 7.84063646873305e-05)
Step 6301: (loss: 0.08511417359113693, loss_fm: 0.08352497220039368, loss_sc: 0.001589201157912612, lr: 7.818055563525524e-05)
Step 6401: (loss: 0.08909780532121658, loss_fm: 0.08561846613883972, loss_sc: 0.0034793405793607235, lr: 7.795543179744914e-05)
Step 6501: (loss: 0.08906204998493195, loss_fm: 0.0837637186050415, loss_sc: 0.005298334173858166, lr: 7.77311096135802e-05)
Step 6601: (loss: 0.09017861634492874, loss_fm: 0.08750470727682114, loss_sc: 0.0026739060413092375, lr: 7.750769145672036e-05)
Step 6701: (loss: 0.09589626640081406, loss_fm: 0.09378226846456528, loss_sc: 0.002113994676619768, lr: 7.728526707287829e-05)
Step 6801: (loss: 0.0898047611117363, loss_fm: 0.08862440288066864, loss_sc: 0.001180358580313623, lr: 7.706391487680206e-05)
Step 6901: (loss: 0.09733996540307999, loss_fm: 0.09673897176980972, loss_sc: 0.0006009910139255226, lr: 7.68437031183534e-05)
Step 7001: (loss: 0.08927380293607712, loss_fm: 0.0864902138710022, loss_sc: 0.0027835911605507135, lr: 7.662469093232998e-05)
Step 7101: (loss: 0.08972274512052536, loss_fm: 0.08813105523586273, loss_sc: 0.0015916910488158464, lr: 7.640692928333003e-05)
Step 7201: (loss: 0.09475910663604736, loss_fm: 0.0914238914847374, loss_sc: 0.003335215151309967, lr: 7.619046181609844e-05)
Step 7301: (loss: 0.08464070409536362, loss_fm: 0.08366695791482925, loss_sc: 0.0009737430955283344, lr: 7.597532562075493e-05)
Step 7401: (loss: 0.09594425559043884, loss_fm: 0.09211232513189316, loss_sc: 0.00383192696608603, lr: 7.576155192136895e-05)
Step 7501: (loss: 0.0898352712392807, loss_fm: 0.0872381255030632, loss_sc: 0.002597144106402993, lr: 7.554916669550399e-05)
Step 7601: (loss: 0.08158494532108307, loss_fm: 0.07841663062572479, loss_sc: 0.003168317023664713, lr: 7.533819123159576e-05)
Step 7701: (loss: 0.08581506460905075, loss_fm: 0.08370040357112885, loss_sc: 0.0021146645303815603, lr: 7.512864263034646e-05)
Step 7801: (loss: 0.08419406414031982, loss_fm: 0.08192064613103867, loss_sc: 0.0022734212689101696, lr: 7.492053425570187e-05)
Step 7901: (loss: 0.08931458741426468, loss_fm: 0.08853525668382645, loss_sc: 0.0007793274126015604, lr: 7.471387614042626e-05)
Step 8001: (loss: 0.08913234621286392, loss_fm: 0.08704305440187454, loss_sc: 0.0020892906468361616, lr: 7.450867535078987e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 8101: (loss: 0.08963413536548615, loss_fm: 0.08294183760881424, loss_sc: 0.006692294497042894, lr: 7.430493631443721e-05)
Step 8201: (loss: 0.08628614991903305, loss_fm: 0.08449126034975052, loss_sc: 0.001794892712496221, lr: 7.41026611150987e-05)
Step 8301: (loss: 0.09354614466428757, loss_fm: 0.0892566367983818, loss_sc: 0.0042895106598734856, lr: 7.390184975744526e-05)
Step 8401: (loss: 0.08317834138870239, loss_fm: 0.08112832903862, loss_sc: 0.0020500088576227427, lr: 7.370250040505814e-05)
Step 8501: (loss: 0.08561398833990097, loss_fm: 0.08373918384313583, loss_sc: 0.0018748074071481824, lr: 7.35046095941902e-05)
Step 8601: (loss: 0.087305948138237, loss_fm: 0.0850086510181427, loss_sc: 0.0022972996812313795, lr: 7.330817242573017e-05)
Step 8701: (loss: 0.0833016037940979, loss_fm: 0.08165330439805984, loss_sc: 0.0016483021900057793, lr: 7.311318273754157e-05)
Step 8801: (loss: 0.08114086091518402, loss_fm: 0.0796053484082222, loss_sc: 0.00153551553376019, lr: 7.291963325913255e-05)
Step 8901: (loss: 0.09492620825767517, loss_fm: 0.09161026775836945, loss_sc: 0.0033159409649670124, lr: 7.272751575041908e-05)
Step 9001: (loss: 0.08564788103103638, loss_fm: 0.08364688605070114, loss_sc: 0.002000996610149741, lr: 7.253682112616832e-05)
Step 9101: (loss: 0.07970862835645676, loss_fm: 0.07872720807790756, loss_sc: 0.000981421791948378, lr: 7.234753956755256e-05)
Step 9201: (loss: 0.08247121423482895, loss_fm: 0.07785388082265854, loss_sc: 0.004617331083863974, lr: 7.215966062210125e-05)
Step 9301: (loss: 0.08026684820652008, loss_fm: 0.07448932528495789, loss_sc: 0.005777521524578333, lr: 7.197317329321146e-05)
Step 9401: (loss: 0.07972448319196701, loss_fm: 0.07901281863451004, loss_sc: 0.0007116658962331712, lr: 7.17880661202619e-05)
Step 9501: (loss: 0.09220067411661148, loss_fm: 0.09095732867717743, loss_sc: 0.0012433486990630627, lr: 7.160432725027182e-05)
Step 9601: (loss: 0.08822321146726608, loss_fm: 0.08679672330617905, loss_sc: 0.0014264901401475072, lr: 7.142194450195255e-05)
Step 9701: (loss: 0.08527442812919617, loss_fm: 0.08267457038164139, loss_sc: 0.002599855186417699, lr: 7.124090542291576e-05)
Step 9801: (loss: 0.09835927933454514, loss_fm: 0.09485950320959091, loss_sc: 0.003499773796647787, lr: 7.106119734072621e-05)
Step 9901: (loss: 0.08454275876283646, loss_fm: 0.08097103238105774, loss_sc: 0.003571723820641637, lr: 7.08828074084189e-05)
Step 10001: (loss: 0.08686976134777069, loss_fm: 0.0841982439160347, loss_sc: 0.0026715185958892107, lr: 7.07057226450383e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 10101: (loss: 0.0891476646065712, loss_fm: 0.08522357791662216, loss_sc: 0.003924085292965174, lr: 7.052992997170311e-05)
Step 10201: (loss: 0.08648291230201721, loss_fm: 0.08596580475568771, loss_sc: 0.0005171069060452282, lr: 7.035541624364849e-05)
Step 10301: (loss: 0.08458153903484344, loss_fm: 0.0813160240650177, loss_sc: 0.003265511943027377, lr: 7.018216827865425e-05)
Step 10401: (loss: 0.08017467707395554, loss_fm: 0.07691290974617004, loss_sc: 0.0032617689575999975, lr: 7.00101728822258e-05)
Step 10501: (loss: 0.07865618169307709, loss_fm: 0.07765951007604599, loss_sc: 0.000996668473817408, lr: 6.98394168698586e-05)
Step 10601: (loss: 0.09608130902051926, loss_fm: 0.09231861680746078, loss_sc: 0.0037626929115504026, lr: 6.966988708668419e-05)
Step 10701: (loss: 0.09288821369409561, loss_fm: 0.08765224367380142, loss_sc: 0.005235970951616764, lr: 6.950157042476573e-05)
Step 10801: (loss: 0.09220980852842331, loss_fm: 0.08953649550676346, loss_sc: 0.0026733148843050003, lr: 6.933445383828432e-05)
Step 10901: (loss: 0.0842185989022255, loss_fm: 0.08077819645404816, loss_sc: 0.003440404310822487, lr: 6.916852435683397e-05)
Step 11001: (loss: 0.07889833301305771, loss_fm: 0.07697661966085434, loss_sc: 0.0019217164954170585, lr: 6.900376909702041e-05)
Step 11101: (loss: 0.08541750907897949, loss_fm: 0.08448049426078796, loss_sc: 0.0009370162733830512, lr: 6.884017527254023e-05)
Step 11201: (loss: 0.08786888420581818, loss_fm: 0.08588289469480515, loss_sc: 0.001985992072150111, lr: 6.867773020289855e-05)
Step 11301: (loss: 0.085061214864254, loss_fm: 0.08257957547903061, loss_sc: 0.0024816414806991816, lr: 6.851642132090852e-05)
Step 11401: (loss: 0.09371074289083481, loss_fm: 0.0872671976685524, loss_sc: 0.006443545687943697, lr: 6.835623617910028e-05)
Step 11501: (loss: 0.07758500427007675, loss_fm: 0.07438302040100098, loss_sc: 0.0032019848003983498, lr: 6.819716245515535e-05)
Step 11601: (loss: 0.08785383403301239, loss_fm: 0.08475624769926071, loss_sc: 0.0030975842382758856, lr: 6.80391879564707e-05)
Step 11701: (loss: 0.0969473272562027, loss_fm: 0.09378337115049362, loss_sc: 0.003163958201184869, lr: 6.788230062394512e-05)
Step 11801: (loss: 0.07799749076366425, loss_fm: 0.07666775584220886, loss_sc: 0.0013297318946570158, lr: 6.772648853507282e-05)
Step 11901: (loss: 0.08305079489946365, loss_fm: 0.08221596479415894, loss_sc: 0.0008348337723873556, lr: 6.757173990641943e-05)
Step 12001: (loss: 0.08884517103433609, loss_fm: 0.08230557292699814, loss_sc: 0.006539595313370228, lr: 6.741804309554841e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 12101: (loss: 0.08149496465921402, loss_fm: 0.07750392705202103, loss_sc: 0.00399103993549943, lr: 6.726538660245902e-05)
Step 12201: (loss: 0.08268925547599792, loss_fm: 0.07976491004228592, loss_sc: 0.0029243463650345802, lr: 6.711375907059091e-05)
Step 12301: (loss: 0.0894860029220581, loss_fm: 0.0884433388710022, loss_sc: 0.001042666845023632, lr: 6.696314928744409e-05)
Step 12401: (loss: 0.08134841918945312, loss_fm: 0.08002761006355286, loss_sc: 0.0013208058662712574, lr: 6.681354618485938e-05)
Step 12501: (loss: 0.08096963167190552, loss_fm: 0.07922308892011642, loss_sc: 0.0017465458950027823, lr: 6.666493883899828e-05)
Step 12601: (loss: 0.07876116782426834, loss_fm: 0.0766095221042633, loss_sc: 0.0021516489796340466, lr: 6.65173164700586e-05)
Step 12701: (loss: 0.07614836096763611, loss_fm: 0.07474333792924881, loss_sc: 0.001405026181600988, lr: 6.637066844175745e-05)
Step 12801: (loss: 0.08499926328659058, loss_fm: 0.08217711746692657, loss_sc: 0.002822142094373703, lr: 6.622498426061052e-05)
Step 12901: (loss: 0.08137544244527817, loss_fm: 0.07861660420894623, loss_sc: 0.002758836606517434, lr: 6.608025357503326e-05)
Step 13001: (loss: 0.08683529496192932, loss_fm: 0.08345213532447815, loss_sc: 0.0033831624314188957, lr: 6.593646617428715e-05)
Step 13101: (loss: 0.08169817179441452, loss_fm: 0.07966120541095734, loss_sc: 0.0020369680132716894, lr: 6.579361198729158e-05)
Step 13201: (loss: 0.09042517095804214, loss_fm: 0.0860661044716835, loss_sc: 0.004359068349003792, lr: 6.565168108131992e-05)
Step 13301: (loss: 0.07576446235179901, loss_fm: 0.07476028800010681, loss_sc: 0.001004176214337349, lr: 6.551066366059622e-05)
Step 13401: (loss: 0.07811535894870758, loss_fm: 0.07675167173147202, loss_sc: 0.001363685354590416, lr: 6.537055006480746e-05)
Step 13501: (loss: 0.08777705579996109, loss_fm: 0.08194876462221146, loss_sc: 0.0058282893151044846, lr: 6.523133076754435e-05)
Step 13601: (loss: 0.08531714975833893, loss_fm: 0.08469323068857193, loss_sc: 0.0006239218055270612, lr: 6.509299637468266e-05)
Step 13701: (loss: 0.07677796483039856, loss_fm: 0.07399320602416992, loss_sc: 0.0027847588062286377, lr: 6.495553762271541e-05)
Step 13801: (loss: 0.08162665367126465, loss_fm: 0.08087167888879776, loss_sc: 0.0007549718720838428, lr: 6.481894537704526e-05)
Step 13901: (loss: 0.07780928164720535, loss_fm: 0.0770014151930809, loss_sc: 0.0008078654063865542, lr: 6.468321063024579e-05)
Step 14001: (loss: 0.0783928632736206, loss_fm: 0.07689341902732849, loss_sc: 0.0014994476223364472, lr: 6.454832450029829e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 14101: (loss: 0.08767373114824295, loss_fm: 0.08707884699106216, loss_sc: 0.0005948846810497344, lr: 6.441427822881156e-05)
Step 14201: (loss: 0.08608434349298477, loss_fm: 0.085479237139225, loss_sc: 0.0006051037344150245, lr: 6.42810631792297e-05)
Step 14301: (loss: 0.08043566346168518, loss_fm: 0.07975200563669205, loss_sc: 0.0006836547399871051, lr: 6.414867083503361e-05)
Step 14401: (loss: 0.07401490211486816, loss_fm: 0.07227906584739685, loss_sc: 0.001735834637656808, lr: 6.401709279794029e-05)
Step 14501: (loss: 0.07911130785942078, loss_fm: 0.07774889469146729, loss_sc: 0.0013624115381389856, lr: 6.388632078610443e-05)
Step 14601: (loss: 0.08777479082345963, loss_fm: 0.08439454436302185, loss_sc: 0.0033802459947764874, lr: 6.375634663232507e-05)
Step 14701: (loss: 0.07872976362705231, loss_fm: 0.07806220650672913, loss_sc: 0.0006675536278635263, lr: 6.36271622822613e-05)
Step 14801: (loss: 0.08138968795537949, loss_fm: 0.07968859374523163, loss_sc: 0.0017010961892083287, lr: 6.349875979265888e-05)
Step 14901: (loss: 0.07925428450107574, loss_fm: 0.07748424261808395, loss_sc: 0.0017700452590361238, lr: 6.337113132959064e-05)
Step 15001: (loss: 0.08011426031589508, loss_fm: 0.07682891935110092, loss_sc: 0.0032853411976248026, lr: 6.32442691667123e-05)
Step 15101: (loss: 0.0856240764260292, loss_fm: 0.08161525428295135, loss_sc: 0.004008824005723, lr: 6.311816568353578e-05)
Step 15201: (loss: 0.08056594431400299, loss_fm: 0.0800677016377449, loss_sc: 0.0004982454120181501, lr: 6.299281336372125e-05)
Step 15301: (loss: 0.08184053748846054, loss_fm: 0.08102098107337952, loss_sc: 0.0008195547270588577, lr: 6.28682047933894e-05)
Step 15401: (loss: 0.07732231914997101, loss_fm: 0.07580634206533432, loss_sc: 0.0015159797621890903, lr: 6.274433265945462e-05)
Step 15501: (loss: 0.08784171938896179, loss_fm: 0.08644361793994904, loss_sc: 0.0013980986550450325, lr: 6.26211897479805e-05)
Step 15601: (loss: 0.08205249905586243, loss_fm: 0.07962360978126526, loss_sc: 0.0024288927670568228, lr: 6.249876894255793e-05)
Step 15701: (loss: 0.08257173746824265, loss_fm: 0.07823004573583603, loss_sc: 0.004341688472777605, lr: 6.237706322270665e-05)
Step 15801: (loss: 0.08695932477712631, loss_fm: 0.0820041373372078, loss_sc: 0.00495518883690238, lr: 6.225606566230061e-05)
Step 15901: (loss: 0.0832790657877922, loss_fm: 0.08191999047994614, loss_sc: 0.00135907216463238, lr: 6.213576942801742e-05)
Step 16001: (loss: 0.07839366793632507, loss_fm: 0.07607588917016983, loss_sc: 0.002317775273695588, lr: 6.201616777781246e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 16101: (loss: 0.08286134153604507, loss_fm: 0.0804729238152504, loss_sc: 0.002388417487964034, lr: 6.18972540594174e-05)
Step 16201: (loss: 0.08360163867473602, loss_fm: 0.080665722489357, loss_sc: 0.00293591246008873, lr: 6.177902170886349e-05)
Step 16301: (loss: 0.08407346904277802, loss_fm: 0.08278629183769226, loss_sc: 0.0012871735962107778, lr: 6.166146424902952e-05)
Step 16401: (loss: 0.08107896149158478, loss_fm: 0.07728320360183716, loss_sc: 0.0037957560271024704, lr: 6.154457528821467e-05)
Step 16501: (loss: 0.07566945999860764, loss_fm: 0.07390342652797699, loss_sc: 0.0017660300945863128, lr: 6.142834851873561e-05)
Step 16601: (loss: 0.08327940851449966, loss_fm: 0.08259765803813934, loss_sc: 0.0006817473913542926, lr: 6.131277771554844e-05)
Step 16701: (loss: 0.07725425809621811, loss_fm: 0.07640348374843597, loss_sc: 0.0008507719030603766, lr: 6.119785673489463e-05)
Step 16801: (loss: 0.07710567116737366, loss_fm: 0.07531246542930603, loss_sc: 0.001793207018636167, lr: 6.108357951297122e-05)
Step 16901: (loss: 0.08110681921243668, loss_fm: 0.08018883317708969, loss_sc: 0.0009179896442219615, lr: 6.0969940064624795e-05)
Step 17001: (loss: 0.07695840299129486, loss_fm: 0.07467418909072876, loss_sc: 0.0022842141333967447, lr: 6.085693248206909e-05)
Step 17101: (loss: 0.07921164482831955, loss_fm: 0.07824042439460754, loss_sc: 0.0009712218889035285, lr: 6.0744550933625835e-05)
Step 17201: (loss: 0.08558978140354156, loss_fm: 0.08131210505962372, loss_sc: 0.004277675878256559, lr: 6.063278966248868e-05)
Step 17301: (loss: 0.08081500232219696, loss_fm: 0.07803717255592346, loss_sc: 0.0027778262738138437, lr: 6.052164298550974e-05)
Step 17401: (loss: 0.08215729147195816, loss_fm: 0.07978323101997375, loss_sc: 0.0023740618489682674, lr: 6.04111052920085e-05)
Step 17501: (loss: 0.08641497790813446, loss_fm: 0.08392047882080078, loss_sc: 0.00249449722468853, lr: 6.0301171042602774e-05)
Step 17601: (loss: 0.08290974050760269, loss_fm: 0.0766584500670433, loss_sc: 0.006251289043575525, lr: 6.01918347680613e-05)
Step 17701: (loss: 0.07809969037771225, loss_fm: 0.07730595767498016, loss_sc: 0.0007937290356494486, lr: 6.00830910681776e-05)
Step 17801: (loss: 0.08481728285551071, loss_fm: 0.08290090411901474, loss_sc: 0.0019163821125403047, lr: 5.997493461066492e-05)
Step 17901: (loss: 0.08040591329336166, loss_fm: 0.07892409712076187, loss_sc: 0.001481817220337689, lr: 5.986736013007151e-05)
Step 18001: (loss: 0.08609628677368164, loss_fm: 0.0844949409365654, loss_sc: 0.0016013479325920343, lr: 5.976036242671647e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 18101: (loss: 0.07526370882987976, loss_fm: 0.07372424006462097, loss_sc: 0.0015394691145047545, lr: 5.9653936365645096e-05)
Step 18201: (loss: 0.08700092881917953, loss_fm: 0.08608025312423706, loss_sc: 0.0009206788381561637, lr: 5.954807687560394e-05)
Step 18301: (loss: 0.07787851989269257, loss_fm: 0.07735700905323029, loss_sc: 0.0005215115961618721, lr: 5.944277894803497e-05)
Step 18401: (loss: 0.076280377805233, loss_fm: 0.07430710643529892, loss_sc: 0.0019732690416276455, lr: 5.933803763608838e-05)
Step 18501: (loss: 0.07891864329576492, loss_fm: 0.07777558267116547, loss_sc: 0.0011430623708292842, lr: 5.923384805365391e-05)
Step 18601: (loss: 0.07929681241512299, loss_fm: 0.07762458175420761, loss_sc: 0.0016722272848710418, lr: 5.913020537441019e-05)
Step 18701: (loss: 0.07851005345582962, loss_fm: 0.07798925042152405, loss_sc: 0.0005208029178902507, lr: 5.9027104830891725e-05)
Step 18801: (loss: 0.0754433125257492, loss_fm: 0.07430621236562729, loss_sc: 0.0011370970169082284, lr: 5.892454171357328e-05)
Step 18901: (loss: 0.07926304638385773, loss_fm: 0.07851637899875641, loss_sc: 0.0007466681418009102, lr: 5.882251136997125e-05)
Step 19001: (loss: 0.08262471109628677, loss_fm: 0.07886150479316711, loss_sc: 0.003763203974813223, lr: 5.8721009203761657e-05)
Step 19101: (loss: 0.08141899108886719, loss_fm: 0.07888348400592804, loss_sc: 0.002535504987463355, lr: 5.86200306739145e-05)
Step 19201: (loss: 0.07483166456222534, loss_fm: 0.07416132837533951, loss_sc: 0.0006703336257487535, lr: 5.8519571293844066e-05)
Step 19301: (loss: 0.08577007800340652, loss_fm: 0.08250575512647629, loss_sc: 0.0032643245067447424, lr: 5.841962663057501e-05)
Step 19401: (loss: 0.08737722039222717, loss_fm: 0.08621780574321747, loss_sc: 0.0011594112729653716, lr: 5.832019230392359e-05)
Step 19501: (loss: 0.07571601867675781, loss_fm: 0.07493768632411957, loss_sc: 0.0007783308392390609, lr: 5.822126398569413e-05)
Step 19601: (loss: 0.08205648511648178, loss_fm: 0.07985226064920425, loss_sc: 0.002204224234446883, lr: 5.8122837398890095e-05)
Step 19701: (loss: 0.0793285071849823, loss_fm: 0.0774150937795639, loss_sc: 0.0019134130561724305, lr: 5.802490831693964e-05)
Step 19801: (loss: 0.08092213422060013, loss_fm: 0.07735743373632431, loss_sc: 0.003564697690308094, lr: 5.792747256293527e-05)
Step 19901: (loss: 0.0721072182059288, loss_fm: 0.07086355239152908, loss_sc: 0.00124366395175457, lr: 5.783052600888734e-05)
Step 20001: (loss: 0.08055825531482697, loss_fm: 0.07639243453741074, loss_sc: 0.004165823571383953, lr: 5.7734064574991106e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 20101: (loss: 0.07386265695095062, loss_fm: 0.07219148427248001, loss_sc: 0.0016711705829948187, lr: 5.7638084228907e-05)
Step 20201: (loss: 0.08519282937049866, loss_fm: 0.08296909928321838, loss_sc: 0.0022237326484173536, lr: 5.754258098505405e-05)
Step 20301: (loss: 0.08630937337875366, loss_fm: 0.08342583477497101, loss_sc: 0.0028835381381213665, lr: 5.744755090391585e-05)
Step 20401: (loss: 0.07953952252864838, loss_fm: 0.07768672704696655, loss_sc: 0.001852793269790709, lr: 5.735299009135911e-05)
Step 20501: (loss: 0.07773507386445999, loss_fm: 0.07684061676263809, loss_sc: 0.0008944590226747096, lr: 5.725889469796439e-05)
Step 20601: (loss: 0.07796499878168106, loss_fm: 0.07568313926458359, loss_sc: 0.002281863009557128, lr: 5.7165260918368785e-05)
Step 20701: (loss: 0.08424793183803558, loss_fm: 0.08103134483098984, loss_sc: 0.003216586308553815, lr: 5.707208499062032e-05)
Step 20801: (loss: 0.07862357795238495, loss_fm: 0.0754479244351387, loss_sc: 0.0031756539829075336, lr: 5.697936319554386e-05)
Step 20901: (loss: 0.07772424817085266, loss_fm: 0.07399222999811172, loss_sc: 0.0037320181727409363, lr: 5.68870918561182e-05)
Step 21001: (loss: 0.08435016125440598, loss_fm: 0.08328860253095627, loss_sc: 0.0010615555802360177, lr: 5.679526733686417e-05)
Step 21101: (loss: 0.07792028039693832, loss_fm: 0.07689206302165985, loss_sc: 0.00102821399923414, lr: 5.67038860432436e-05)
Step 21201: (loss: 0.07850628346204758, loss_fm: 0.07664002478122711, loss_sc: 0.0018662563525140285, lr: 5.661294442106871e-05)
Step 21301: (loss: 0.079954594373703, loss_fm: 0.07830750197172165, loss_sc: 0.0016470957780256867, lr: 5.652243895592202e-05)
Step 21401: (loss: 0.0718243420124054, loss_fm: 0.07068587094545364, loss_sc: 0.0011384696699678898, lr: 5.6432366172586174e-05)
Step 21501: (loss: 0.07598284631967545, loss_fm: 0.0711163803935051, loss_sc: 0.00486646918579936, lr: 5.634272263448389e-05)
Step 21601: (loss: 0.08749902993440628, loss_fm: 0.08586085587739944, loss_sc: 0.0016381720779463649, lr: 5.6253504943127626e-05)
Step 21701: (loss: 0.07988190650939941, loss_fm: 0.07832924276590347, loss_sc: 0.0015526614151895046, lr: 5.616470973757854e-05)
Step 21801: (loss: 0.08092029392719269, loss_fm: 0.08003708720207214, loss_sc: 0.0008832046878524125, lr: 5.6076333693915154e-05)
Step 21901: (loss: 0.08425067365169525, loss_fm: 0.07913130521774292, loss_sc: 0.005119369365274906, lr: 5.598837352471085e-05)
Step 22001: (loss: 0.07977325469255447, loss_fm: 0.07636406272649765, loss_sc: 0.003409189870581031, lr: 5.59008259785205e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 22101: (loss: 0.09107836335897446, loss_fm: 0.08923429250717163, loss_sc: 0.0018440720159560442, lr: 5.581368783937582e-05)
Step 22201: (loss: 0.07539192587137222, loss_fm: 0.07509128749370575, loss_sc: 0.00030064035672694445, lr: 5.5726955926289455e-05)
Step 22301: (loss: 0.08185096085071564, loss_fm: 0.07970913499593735, loss_sc: 0.002141822362318635, lr: 5.564062709276725e-05)
Step 22401: (loss: 0.07846469432115555, loss_fm: 0.07735707610845566, loss_sc: 0.0011076218215748668, lr: 5.555469822632904e-05)
Step 22501: (loss: 0.07881853729486465, loss_fm: 0.07537166774272919, loss_sc: 0.003446872578933835, lr: 5.546916624803742e-05)
Step 22601: (loss: 0.08867692947387695, loss_fm: 0.08612525463104248, loss_sc: 0.0025516736786812544, lr: 5.538402811203454e-05)
Step 22701: (loss: 0.0806872546672821, loss_fm: 0.0777258425951004, loss_sc: 0.0029614113736897707, lr: 5.529928080508654e-05)
Step 22801: (loss: 0.07896346598863602, loss_fm: 0.07819187641143799, loss_sc: 0.000771589984651655, lr: 5.521492134613582e-05)
Step 22901: (loss: 0.07925812900066376, loss_fm: 0.07365911453962326, loss_sc: 0.005599017720669508, lr: 5.5130946785860604e-05)
Step 23001: (loss: 0.08618710935115814, loss_fm: 0.08513904362916946, loss_sc: 0.0010480626951903105, lr: 5.504735420624202e-05)
Step 23101: (loss: 0.07659055292606354, loss_fm: 0.0723317563533783, loss_sc: 0.004258793778717518, lr: 5.496414072013818e-05)
Step 23201: (loss: 0.08384402096271515, loss_fm: 0.08303810656070709, loss_sc: 0.0008059162646532059, lr: 5.488130347086552e-05)
Step 23301: (loss: 0.07768501341342926, loss_fm: 0.07494654506444931, loss_sc: 0.002738465555012226, lr: 5.479883963178689e-05)
Step 23401: (loss: 0.0745280310511589, loss_fm: 0.07268023490905762, loss_sc: 0.0018477957928553224, lr: 5.471674640590649e-05)
Step 23501: (loss: 0.07893785089254379, loss_fm: 0.0750427395105362, loss_sc: 0.0038951109163463116, lr: 5.46350210254715e-05)
Step 23601: (loss: 0.08551773428916931, loss_fm: 0.08407896757125854, loss_sc: 0.001438769162632525, lr: 5.455366075158013e-05)
Step 23701: (loss: 0.07554715126752853, loss_fm: 0.07389099895954132, loss_sc: 0.0016561511438339949, lr: 5.447266287379619e-05)
Step 23801: (loss: 0.0868460163474083, loss_fm: 0.08343882113695145, loss_sc: 0.003407194744795561, lr: 5.43920247097698e-05)
Step 23901: (loss: 0.08567049354314804, loss_fm: 0.08300547301769257, loss_sc: 0.002665022388100624, lr: 5.431174360486439e-05)
Step 24001: (loss: 0.08063958585262299, loss_fm: 0.08012367784976959, loss_sc: 0.0005159115535207093, lr: 5.423181693178967e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 24101: (loss: 0.08136676996946335, loss_fm: 0.07464193552732468, loss_sc: 0.006724831648170948, lr: 5.4152242090240425e-05)
Step 24201: (loss: 0.07366783171892166, loss_fm: 0.07284589111804962, loss_sc: 0.0008219432784244418, lr: 5.4073016506541335e-05)
Step 24301: (loss: 0.08246511965990067, loss_fm: 0.0794193223118782, loss_sc: 0.003045795951038599, lr: 5.399413763329733e-05)
Step 24401: (loss: 0.06851941347122192, loss_fm: 0.06817999482154846, loss_sc: 0.0003394191444385797, lr: 5.391560294904957e-05)
Step 24501: (loss: 0.07368850708007812, loss_fm: 0.07073470205068588, loss_sc: 0.0029538078233599663, lr: 5.383740995793695e-05)
Step 24601: (loss: 0.0719352513551712, loss_fm: 0.06931513547897339, loss_sc: 0.002620117273181677, lr: 5.375955618936293e-05)
Step 24701: (loss: 0.07607096433639526, loss_fm: 0.07482358813285828, loss_sc: 0.0012473778333514929, lr: 5.368203919766772e-05)
Step 24801: (loss: 0.07955386489629745, loss_fm: 0.07788139581680298, loss_sc: 0.0016724723391234875, lr: 5.360485656180559e-05)
Step 24901: (loss: 0.0769001692533493, loss_fm: 0.07570739090442657, loss_sc: 0.0011927791638299823, lr: 5.35280058850273e-05)
Step 25001: (loss: 0.08184368908405304, loss_fm: 0.07882124185562134, loss_sc: 0.003022446995601058, lr: 5.345148479456746e-05)
Step 25101: (loss: 0.0762433409690857, loss_fm: 0.07378017157316208, loss_sc: 0.002463171724230051, lr: 5.3375290941336937e-05)
Step 25201: (loss: 0.07860101014375687, loss_fm: 0.07752608507871628, loss_sc: 0.001074924599379301, lr: 5.329942199961987e-05)
Step 25301: (loss: 0.07706318795681, loss_fm: 0.07508757710456848, loss_sc: 0.001975612947717309, lr: 5.32238756667756e-05)
Step 25401: (loss: 0.07376480847597122, loss_fm: 0.06973543763160706, loss_sc: 0.004029370378702879, lr: 5.314864966294508e-05)
Step 25501: (loss: 0.07286206632852554, loss_fm: 0.07182677835226059, loss_sc: 0.0010352900717407465, lr: 5.307374173076197e-05)
Step 25601: (loss: 0.07769559323787689, loss_fm: 0.07664331048727036, loss_sc: 0.0010522837983444333, lr: 5.299914963506808e-05)
Step 25701: (loss: 0.08431376516819, loss_fm: 0.0794457271695137, loss_sc: 0.004868040326982737, lr: 5.292487116263326e-05)
Step 25801: (loss: 0.07686184346675873, loss_fm: 0.07601195573806763, loss_sc: 0.0008498853421770036, lr: 5.28509041218796e-05)
Step 25901: (loss: 0.07172590494155884, loss_fm: 0.07085733860731125, loss_sc: 0.000868565053679049, lr: 5.277724634260983e-05)
Step 26001: (loss: 0.07648611813783646, loss_fm: 0.07573480159044266, loss_sc: 0.0007513174205087125, lr: 5.270389567573993e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 26101: (loss: 0.07229109108448029, loss_fm: 0.06955175846815109, loss_sc: 0.002739331452175975, lr: 5.2630849993035696e-05)
Step 26201: (loss: 0.07474236935377121, loss_fm: 0.07286398857831955, loss_sc: 0.0018783832201734185, lr: 5.255810718685345e-05)
Step 26301: (loss: 0.07696551829576492, loss_fm: 0.07457931339740753, loss_sc: 0.0023862060625106096, lr: 5.248566516988459e-05)
Step 26401: (loss: 0.07394386827945709, loss_fm: 0.07205724716186523, loss_sc: 0.0018866208847612143, lr: 5.241352187490406e-05)
Step 26501: (loss: 0.07910636812448502, loss_fm: 0.07860881090164185, loss_sc: 0.0004975582705810666, lr: 5.2341675254522524e-05)
Step 26601: (loss: 0.08531797677278519, loss_fm: 0.08427157253026962, loss_sc: 0.0010464050574228168, lr: 5.22701232809424e-05)
Step 26701: (loss: 0.07413739711046219, loss_fm: 0.0727510079741478, loss_sc: 0.0013863872736692429, lr: 5.219886394571741e-05)
Step 26801: (loss: 0.07489852607250214, loss_fm: 0.07279502600431442, loss_sc: 0.002103500533849001, lr: 5.212789525951587e-05)
Step 26901: (loss: 0.07615573704242706, loss_fm: 0.07522997260093689, loss_sc: 0.0009257674100808799, lr: 5.2057215251887346e-05)
Step 27001: (loss: 0.0766231045126915, loss_fm: 0.07551517337560654, loss_sc: 0.0011079303221777081, lr: 5.198682197103292e-05)
Step 27101: (loss: 0.08010786026716232, loss_fm: 0.07794763147830963, loss_sc: 0.002160230651497841, lr: 5.191671348357883e-05)
Step 27201: (loss: 0.07933328300714493, loss_fm: 0.07882006466388702, loss_sc: 0.0005132154328748584, lr: 5.184688787435339e-05)
Step 27301: (loss: 0.0770452693104744, loss_fm: 0.07646102458238602, loss_sc: 0.0005842416430823505, lr: 5.17773432461673e-05)
Step 27401: (loss: 0.08251310884952545, loss_fm: 0.08143085241317749, loss_sc: 0.0010822548065334558, lr: 5.170807771959712e-05)
Step 27501: (loss: 0.08035624772310257, loss_fm: 0.07477613538503647, loss_sc: 0.005580115132033825, lr: 5.1639089432771916e-05)
Step 27601: (loss: 0.07952581346035004, loss_fm: 0.07657082378864288, loss_sc: 0.0029549889732152224, lr: 5.157037654116314e-05)
Step 27701: (loss: 0.08720509707927704, loss_fm: 0.08168933540582657, loss_sc: 0.005515763070434332, lr: 5.1501937217377396e-05)
Step 27801: (loss: 0.0853312760591507, loss_fm: 0.0843125581741333, loss_sc: 0.0010187206789851189, lr: 5.143376965095237e-05)
Step 27901: (loss: 0.08384737372398376, loss_fm: 0.08237836509943008, loss_sc: 0.001469007576815784, lr: 5.1365872048155686e-05)
Step 28001: (loss: 0.08211750537157059, loss_fm: 0.08049288392066956, loss_sc: 0.0016246180748566985, lr: 5.129824263178664e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 28101: (loss: 0.08203183859586716, loss_fm: 0.07646648585796356, loss_sc: 0.005565354600548744, lr: 5.1230879640980826e-05)
Step 28201: (loss: 0.08195322006940842, loss_fm: 0.07770318537950516, loss_sc: 0.004250035621225834, lr: 5.1163781331017556e-05)
Step 28301: (loss: 0.08089437335729599, loss_fm: 0.07853855192661285, loss_sc: 0.002355818636715412, lr: 5.1096945973130104e-05)
Step 28401: (loss: 0.0795430839061737, loss_fm: 0.07750499248504639, loss_sc: 0.002038095146417618, lr: 5.103037185431859e-05)
Step 28501: (loss: 0.07506191730499268, loss_fm: 0.0724019706249237, loss_sc: 0.0026599441189318895, lr: 5.0964057277165604e-05)
Step 28601: (loss: 0.07530012726783752, loss_fm: 0.07437339425086975, loss_sc: 0.0009267316781915724, lr: 5.08980005596544e-05)
Step 28701: (loss: 0.07490233331918716, loss_fm: 0.07237200438976288, loss_sc: 0.002530330792069435, lr: 5.0832200034989736e-05)
Step 28801: (loss: 0.08275964111089706, loss_fm: 0.07914705574512482, loss_sc: 0.003612586995586753, lr: 5.0766654051421226e-05)
Step 28901: (loss: 0.07638605684041977, loss_fm: 0.07500126957893372, loss_sc: 0.0013847856316715479, lr: 5.070136097206917e-05)
Step 29001: (loss: 0.07602962106466293, loss_fm: 0.07114388048648834, loss_sc: 0.0048857396468520164, lr: 5.063631917475287e-05)
Step 29101: (loss: 0.07735797762870789, loss_fm: 0.0766885057091713, loss_sc: 0.0006694740150123835, lr: 5.057152705182141e-05)
Step 29201: (loss: 0.08163144439458847, loss_fm: 0.07854344695806503, loss_sc: 0.003087995108217001, lr: 5.050698300998663e-05)
Step 29301: (loss: 0.0815562978386879, loss_fm: 0.07877490669488907, loss_sc: 0.0027813913766294718, lr: 5.0442685470158725e-05)
Step 29401: (loss: 0.08097398281097412, loss_fm: 0.07817521691322327, loss_sc: 0.00279876752756536, lr: 5.0378632867283845e-05)
Step 29501: (loss: 0.08269856125116348, loss_fm: 0.08045011758804321, loss_sc: 0.002248443430289626, lr: 5.031482365018416e-05)
Step 29601: (loss: 0.08040443062782288, loss_fm: 0.07854952663183212, loss_sc: 0.0018549059750512242, lr: 5.025125628140014e-05)
Step 29701: (loss: 0.08472101390361786, loss_fm: 0.08185520768165588, loss_sc: 0.0028658092487603426, lr: 5.018792923703481e-05)
Step 29801: (loss: 0.08140426129102707, loss_fm: 0.07818472385406494, loss_sc: 0.0032195409294217825, lr: 5.0124841006600464e-05)
Step 29901: (loss: 0.07534480094909668, loss_fm: 0.07446154952049255, loss_sc: 0.0008832506719045341, lr: 5.0061990092867224e-05)
Step 30001: (loss: 0.07921018451452255, loss_fm: 0.07703832536935806, loss_sc: 0.0021718612406402826, lr: 4.999937501171391e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 30101: (loss: 0.07917706668376923, loss_fm: 0.07777083665132523, loss_sc: 0.001406232942827046, lr: 4.9936994291980744e-05)
Step 30201: (loss: 0.07614142447710037, loss_fm: 0.07475917786359787, loss_sc: 0.0013822463806718588, lr: 4.9874846475324266e-05)
Step 30301: (loss: 0.07740940898656845, loss_fm: 0.07377013564109802, loss_sc: 0.0036392700858414173, lr: 4.981293011607402e-05)
Step 30401: (loss: 0.07758143544197083, loss_fm: 0.07733959704637527, loss_sc: 0.00024183531058952212, lr: 4.975124378109147e-05)
Step 30501: (loss: 0.08750978112220764, loss_fm: 0.08150113373994827, loss_sc: 0.006008648779243231, lr: 4.96897860496305e-05)
Step 30601: (loss: 0.07990320771932602, loss_fm: 0.07674349844455719, loss_sc: 0.0031597057823091745, lr: 4.962855551320013e-05)
Step 30701: (loss: 0.07917741686105728, loss_fm: 0.07755348086357117, loss_sc: 0.0016239382093772292, lr: 4.9567550775428854e-05)
Step 30801: (loss: 0.08127637952566147, loss_fm: 0.07942931354045868, loss_sc: 0.001847064238972962, lr: 4.950677045193087e-05)
Step 30901: (loss: 0.08187111467123032, loss_fm: 0.07968326658010483, loss_sc: 0.0021878457628190517, lr: 4.9446213170174215e-05)
Step 31001: (loss: 0.07805774360895157, loss_fm: 0.07332267612218857, loss_sc: 0.004735066555440426, lr: 4.93858775693505e-05)
Step 31101: (loss: 0.08125095069408417, loss_fm: 0.07990762591362, loss_sc: 0.0013433238491415977, lr: 4.932576230024654e-05)
Step 31201: (loss: 0.07317210733890533, loss_fm: 0.06891702115535736, loss_sc: 0.0042550889775156975, lr: 4.92658660251176e-05)
Step 31301: (loss: 0.07693178206682205, loss_fm: 0.0740932896733284, loss_sc: 0.0028384921606630087, lr: 4.9206187417562355e-05)
Step 31401: (loss: 0.07814768701791763, loss_fm: 0.07787194103002548, loss_sc: 0.0002757442416623235, lr: 4.914672516239955e-05)
Step 31501: (loss: 0.07832891494035721, loss_fm: 0.0777665451169014, loss_sc: 0.0005623705801554024, lr: 4.9087477955546234e-05)
Step 31601: (loss: 0.07844892889261246, loss_fm: 0.07761476188898087, loss_sc: 0.0008341681095771492, lr: 4.9028444503897685e-05)
Step 31701: (loss: 0.07916798442602158, loss_fm: 0.07484187930822372, loss_sc: 0.0043261051177978516, lr: 4.896962352520879e-05)
Step 31801: (loss: 0.07629147171974182, loss_fm: 0.07544630765914917, loss_sc: 0.0008451627218164504, lr: 4.891101374797717e-05)
Step 31901: (loss: 0.08069293200969696, loss_fm: 0.07785092294216156, loss_sc: 0.0028420104645192623, lr: 4.885261391132764e-05)
Step 32001: (loss: 0.07796970754861832, loss_fm: 0.07686229795217514, loss_sc: 0.0011074120411649346, lr: 4.8794422764898366e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 32101: (loss: 0.08387294411659241, loss_fm: 0.08138108253479004, loss_sc: 0.002491861581802368, lr: 4.873643906872837e-05)
Step 32201: (loss: 0.07872539758682251, loss_fm: 0.07763645052909851, loss_sc: 0.0010889448458328843, lr: 4.867866159314656e-05)
Step 32301: (loss: 0.07533269375562668, loss_fm: 0.07257368415594101, loss_sc: 0.0027590119279921055, lr: 4.862108911866224e-05)
Step 32401: (loss: 0.0812641829252243, loss_fm: 0.08061448484659195, loss_sc: 0.0006496969726867974, lr: 4.856372043585695e-05)
Step 32501: (loss: 0.07736392319202423, loss_fm: 0.0767519623041153, loss_sc: 0.000611960596870631, lr: 4.850655434527781e-05)
Step 32601: (loss: 0.0797930434346199, loss_fm: 0.07921137660741806, loss_sc: 0.0005816691555082798, lr: 4.8449589657332154e-05)
Step 32701: (loss: 0.0785207450389862, loss_fm: 0.07737275213003159, loss_sc: 0.0011479895329102874, lr: 4.8392825192183546e-05)
Step 32801: (loss: 0.08333595842123032, loss_fm: 0.07555026561021805, loss_sc: 0.007785691414028406, lr: 4.833625977964921e-05)
Step 32901: (loss: 0.07284329831600189, loss_fm: 0.07196985185146332, loss_sc: 0.0008734446601010859, lr: 4.827989225909865e-05)
Step 33001: (loss: 0.08229295164346695, loss_fm: 0.0806431993842125, loss_sc: 0.0016497514443472028, lr: 4.8223721479353646e-05)
Step 33101: (loss: 0.07273924350738525, loss_fm: 0.07207372784614563, loss_sc: 0.000665517000015825, lr: 4.816774629858951e-05)
Step 33201: (loss: 0.07644007354974747, loss_fm: 0.06902826577425003, loss_sc: 0.00741181056946516, lr: 4.8111965584237594e-05)
Step 33301: (loss: 0.07512684911489487, loss_fm: 0.07342863082885742, loss_sc: 0.0016982193337753415, lr: 4.8056378212889076e-05)
Step 33401: (loss: 0.07377802580595016, loss_fm: 0.07251636683940887, loss_sc: 0.001261659781448543, lr: 4.800098307019987e-05)
Step 33501: (loss: 0.07270897924900055, loss_fm: 0.07075822353363037, loss_sc: 0.0019507529214024544, lr: 4.7945779050796864e-05)
Step 33601: (loss: 0.07199274748563766, loss_fm: 0.0712776631116867, loss_sc: 0.0007150840247049928, lr: 4.7890765058185224e-05)
Step 33701: (loss: 0.08091883361339569, loss_fm: 0.07945269346237183, loss_sc: 0.0014661402674391866, lr: 4.783594000465696e-05)
Step 33801: (loss: 0.0775851234793663, loss_fm: 0.07696376740932465, loss_sc: 0.0006213546148501337, lr: 4.778130281120058e-05)
Step 33901: (loss: 0.07301054894924164, loss_fm: 0.07200385630130768, loss_sc: 0.0010066891554743052, lr: 4.7726852407411925e-05)
Step 34001: (loss: 0.07533763349056244, loss_fm: 0.07258495688438416, loss_sc: 0.002752673113718629, lr: 4.767258773140604e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 34101: (loss: 0.08372685313224792, loss_fm: 0.07824531942605972, loss_sc: 0.0054815346375107765, lr: 4.761850772973024e-05)
Step 34201: (loss: 0.07664851099252701, loss_fm: 0.07271628081798553, loss_sc: 0.003932227846235037, lr: 4.75646113572782e-05)
Step 34301: (loss: 0.07285510748624802, loss_fm: 0.06891221553087234, loss_sc: 0.003942893818020821, lr: 4.751089757720511e-05)
Step 34401: (loss: 0.07947535067796707, loss_fm: 0.07805965840816498, loss_sc: 0.0014156925026327372, lr: 4.7457365360843945e-05)
Step 34501: (loss: 0.08111816644668579, loss_fm: 0.07271485775709152, loss_sc: 0.008403305895626545, lr: 4.740401368762267e-05)
Step 34601: (loss: 0.07625526934862137, loss_fm: 0.07195170968770981, loss_sc: 0.0043035573326051235, lr: 4.735084154498255e-05)
Step 34701: (loss: 0.07866978645324707, loss_fm: 0.07841287553310394, loss_sc: 0.00025691435439512134, lr: 4.729784792829742e-05)
Step 34801: (loss: 0.0774124339222908, loss_fm: 0.07520870119333267, loss_sc: 0.0022037322632968426, lr: 4.7245031840794e-05)
Step 34901: (loss: 0.073049396276474, loss_fm: 0.07135936617851257, loss_sc: 0.0016900323098525405, lr: 4.719239229347308e-05)
Step 35001: (loss: 0.07466742396354675, loss_fm: 0.07237278670072556, loss_sc: 0.0022946400567889214, lr: 4.713992830503181e-05)
Step 35101: (loss: 0.07538224756717682, loss_fm: 0.07131237536668777, loss_sc: 0.004069873597472906, lr: 4.708763890178683e-05)
Step 35201: (loss: 0.07498901337385178, loss_fm: 0.06999129056930542, loss_sc: 0.004997721873223782, lr: 4.703552311759834e-05)
Step 35301: (loss: 0.07943668961524963, loss_fm: 0.0788075402379036, loss_sc: 0.0006291473400779068, lr: 4.6983579993795206e-05)
Step 35401: (loss: 0.08150686323642731, loss_fm: 0.07828287035226822, loss_sc: 0.003223991021513939, lr: 4.6931808579100826e-05)
Step 35501: (loss: 0.07885745167732239, loss_fm: 0.07845927774906158, loss_sc: 0.0003981705813203007, lr: 4.688020792955998e-05)
Step 35601: (loss: 0.07792636752128601, loss_fm: 0.07702438533306122, loss_sc: 0.0009019820136018097, lr: 4.6828777108466545e-05)
Step 35701: (loss: 0.07864972949028015, loss_fm: 0.0782565027475357, loss_sc: 0.0003932241233997047, lr: 4.677751518629206e-05)
Step 35801: (loss: 0.07864251732826233, loss_fm: 0.07801055163145065, loss_sc: 0.000631968374364078, lr: 4.67264212406152e-05)
Step 35901: (loss: 0.07484292984008789, loss_fm: 0.07275088131427765, loss_sc: 0.0020920466631650925, lr: 4.667549435605201e-05)
Step 36001: (loss: 0.07858655601739883, loss_fm: 0.07608966529369354, loss_sc: 0.0024968902580440044, lr: 4.6624733624187074e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 36101: (loss: 0.07687138766050339, loss_fm: 0.07514853775501251, loss_sc: 0.0017228504875674844, lr: 4.6574138143505436e-05)
Step 36201: (loss: 0.07733741402626038, loss_fm: 0.07652654498815536, loss_sc: 0.0008108677575364709, lr: 4.6523707019325364e-05)
Step 36301: (loss: 0.07798092067241669, loss_fm: 0.07527432590723038, loss_sc: 0.002706595230847597, lr: 4.647343936373187e-05)
Step 36401: (loss: 0.08323902636766434, loss_fm: 0.07976316660642624, loss_sc: 0.003475857898592949, lr: 4.64233342955111e-05)
Step 36501: (loss: 0.07985270768404007, loss_fm: 0.07562945783138275, loss_sc: 0.004223252180963755, lr: 4.637339094008538e-05)
Step 36601: (loss: 0.07448656857013702, loss_fm: 0.07194115966558456, loss_sc: 0.002545409370213747, lr: 4.63236084294492e-05)
Step 36701: (loss: 0.07848216593265533, loss_fm: 0.07782470434904099, loss_sc: 0.0006574614671990275, lr: 4.627398590210574e-05)
Step 36801: (loss: 0.08428987860679626, loss_fm: 0.08342120051383972, loss_sc: 0.0008686805958859622, lr: 4.6224522503004354e-05)
Step 36901: (loss: 0.07264239341020584, loss_fm: 0.0717335119843483, loss_sc: 0.0009088848601095378, lr: 4.61752173834786e-05)
Step 37001: (loss: 0.08565240353345871, loss_fm: 0.079143226146698, loss_sc: 0.006509177852421999, lr: 4.612606970118518e-05)
Step 37101: (loss: 0.07362678647041321, loss_fm: 0.07169395685195923, loss_sc: 0.0019328300841152668, lr: 4.60770786200434e-05)
Step 37201: (loss: 0.08445349335670471, loss_fm: 0.08107749372720718, loss_sc: 0.0033759993966668844, lr: 4.6028243310175495e-05)
Step 37301: (loss: 0.07725682854652405, loss_fm: 0.07289493829011917, loss_sc: 0.004361889325082302, lr: 4.597956294784756e-05)
Step 37401: (loss: 0.07725435495376587, loss_fm: 0.07423663139343262, loss_sc: 0.0030177226290106773, lr: 4.5931036715411206e-05)
Step 37501: (loss: 0.07672301679849625, loss_fm: 0.07427480071783066, loss_sc: 0.002448219573125243, lr: 4.5882663801245876e-05)
Step 37601: (loss: 0.08042848110198975, loss_fm: 0.07682985812425613, loss_sc: 0.0035986227449029684, lr: 4.58344433997018e-05)
Step 37701: (loss: 0.07574385404586792, loss_fm: 0.07425082474946976, loss_sc: 0.0014930329052731395, lr: 4.578637471104369e-05)
Step 37801: (loss: 0.07841134816408157, loss_fm: 0.07568097114562988, loss_sc: 0.002730379579588771, lr: 4.5738456941395015e-05)
Step 37901: (loss: 0.08611444383859634, loss_fm: 0.07651758193969727, loss_sc: 0.009596860967576504, lr: 4.56906893026829e-05)
Step 38001: (loss: 0.07676203548908234, loss_fm: 0.07317642867565155, loss_sc: 0.0035856065806001425, lr: 4.5643071012583736e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 38101: (loss: 0.07787054032087326, loss_fm: 0.07620752602815628, loss_sc: 0.0016630113823339343, lr: 4.5595601294469314e-05)
Step 38201: (loss: 0.08360839635133743, loss_fm: 0.07726862281560898, loss_sc: 0.0063397749327123165, lr: 4.5548279377353695e-05)
Step 38301: (loss: 0.07497292757034302, loss_fm: 0.0732731893658638, loss_sc: 0.001699737273156643, lr: 4.550110449584055e-05)
Step 38401: (loss: 0.07993083447217941, loss_fm: 0.07755148410797119, loss_sc: 0.0023793501313775778, lr: 4.5454075890071193e-05)
Step 38501: (loss: 0.08042429387569427, loss_fm: 0.07625433057546616, loss_sc: 0.0041699642315506935, lr: 4.5407192805673175e-05)
Step 38601: (loss: 0.08155574649572372, loss_fm: 0.07830667495727539, loss_sc: 0.0032490710727870464, lr: 4.536045449370947e-05)
Step 38701: (loss: 0.07901540398597717, loss_fm: 0.0778728649020195, loss_sc: 0.0011425353586673737, lr: 4.5313860210628204e-05)
Step 38801: (loss: 0.07292161881923676, loss_fm: 0.07214631885290146, loss_sc: 0.0007753000245429575, lr: 4.526740921821298e-05)
Step 38901: (loss: 0.08319846540689468, loss_fm: 0.07719064503908157, loss_sc: 0.006007819902151823, lr: 4.522110078353377e-05)
Step 39001: (loss: 0.07389167696237564, loss_fm: 0.07337026298046112, loss_sc: 0.0005214164848439395, lr: 4.517493417889831e-05)
Step 39101: (loss: 0.07439577579498291, loss_fm: 0.07349982112646103, loss_sc: 0.0008959537371993065, lr: 4.512890868180412e-05)
Step 39201: (loss: 0.07402435690164566, loss_fm: 0.07278196513652802, loss_sc: 0.0012423921143636107, lr: 4.5083023574890956e-05)
Step 39301: (loss: 0.07775550335645676, loss_fm: 0.0750349685549736, loss_sc: 0.0027205334044992924, lr: 4.503727814589391e-05)
Step 39401: (loss: 0.07657970488071442, loss_fm: 0.0744718462228775, loss_sc: 0.0021078563295304775, lr: 4.499167168759691e-05)
Step 39501: (loss: 0.0803544670343399, loss_fm: 0.07688567787408829, loss_sc: 0.0034687870647758245, lr: 4.494620349778686e-05)
Step 39601: (loss: 0.07906416058540344, loss_fm: 0.07099603116512299, loss_sc: 0.008068125694990158, lr: 4.490087287920817e-05)
Step 39701: (loss: 0.07717153429985046, loss_fm: 0.07606084644794464, loss_sc: 0.0011106892488896847, lr: 4.485567913951792e-05)
Step 39801: (loss: 0.08174903690814972, loss_fm: 0.08034387230873108, loss_sc: 0.0014051614562049508, lr: 4.4810621591241355e-05)
Step 39901: (loss: 0.07797848433256149, loss_fm: 0.07562869042158127, loss_sc: 0.0023497946094721556, lr: 4.4765699551728044e-05)
Step 40001: (loss: 0.08518055826425552, loss_fm: 0.08068668842315674, loss_sc: 0.004493872635066509, lr: 4.472091234310839e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 40101: (loss: 0.07514087855815887, loss_fm: 0.0748542845249176, loss_sc: 0.0002865944989025593, lr: 4.4676259292250686e-05)
Step 40201: (loss: 0.07782473415136337, loss_fm: 0.07662476599216461, loss_sc: 0.00119996746070683, lr: 4.4631739730718656e-05)
Step 40301: (loss: 0.08044401556253433, loss_fm: 0.07783205062150955, loss_sc: 0.0026119614485651255, lr: 4.458735299472934e-05)
Step 40401: (loss: 0.08160606026649475, loss_fm: 0.07922620326280594, loss_sc: 0.0023798560723662376, lr: 4.454309842511161e-05)
Step 40501: (loss: 0.08051880449056625, loss_fm: 0.07392574846744537, loss_sc: 0.006593058817088604, lr: 4.449897536726504e-05)
Step 40601: (loss: 0.07443663477897644, loss_fm: 0.07338713854551315, loss_sc: 0.0010494999587535858, lr: 4.44549831711192e-05)
Step 40701: (loss: 0.07398021221160889, loss_fm: 0.0726817324757576, loss_sc: 0.001298481016419828, lr: 4.441112119109347e-05)
Step 40801: (loss: 0.07218991965055466, loss_fm: 0.06680001318454742, loss_sc: 0.005389906000345945, lr: 4.436738878605722e-05)
Step 40901: (loss: 0.07845679670572281, loss_fm: 0.07639896124601364, loss_sc: 0.0020578368566930294, lr: 4.4323785319290475e-05)
Step 41001: (loss: 0.08048379421234131, loss_fm: 0.07826007157564163, loss_sc: 0.0022237207740545273, lr: 4.428031015844496e-05)
Step 41101: (loss: 0.07376062870025635, loss_fm: 0.07285907119512558, loss_sc: 0.0009015558753162622, lr: 4.42369626755056e-05)
Step 41201: (loss: 0.08222995698451996, loss_fm: 0.08197974413633347, loss_sc: 0.0002502123825252056, lr: 4.41937422467524e-05)
Step 41301: (loss: 0.0687396451830864, loss_fm: 0.06779976934194565, loss_sc: 0.0009398749680258334, lr: 4.415064825272275e-05)
Step 41401: (loss: 0.08283238112926483, loss_fm: 0.08037632703781128, loss_sc: 0.002456052927300334, lr: 4.410768007817417e-05)
Step 41501: (loss: 0.078078992664814, loss_fm: 0.07545311748981476, loss_sc: 0.0026258747093379498, lr: 4.406483711204738e-05)
Step 41601: (loss: 0.08251994848251343, loss_fm: 0.07674645632505417, loss_sc: 0.005773494485765696, lr: 4.4022118747429797e-05)
Step 41701: (loss: 0.07730820775032043, loss_fm: 0.07402556389570236, loss_sc: 0.0032826431561261415, lr: 4.397952438151947e-05)
Step 41801: (loss: 0.08412987738847733, loss_fm: 0.08207005262374878, loss_sc: 0.0020598224364221096, lr: 4.393705341558929e-05)
Step 41901: (loss: 0.07434963434934616, loss_fm: 0.07252202183008194, loss_sc: 0.001827612635679543, lr: 4.3894705254951725e-05)
Step 42001: (loss: 0.07737269252538681, loss_fm: 0.07611045241355896, loss_sc: 0.0012622397625818849, lr: 4.3852479308923754e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 42101: (loss: 0.07630010694265366, loss_fm: 0.07345027476549149, loss_sc: 0.0028498333413153887, lr: 4.381037499079233e-05)
Step 42201: (loss: 0.077974334359169, loss_fm: 0.07485499978065491, loss_sc: 0.0031193355098366737, lr: 4.376839171778012e-05)
Step 42301: (loss: 0.08239953964948654, loss_fm: 0.0799231305718422, loss_sc: 0.002476411173120141, lr: 4.37265289110116e-05)
Step 42401: (loss: 0.07829154282808304, loss_fm: 0.07604407519102097, loss_sc: 0.0022474657744169235, lr: 4.3684785995479596e-05)
Step 42501: (loss: 0.08065720647573471, loss_fm: 0.07987824827432632, loss_sc: 0.0007789553492330015, lr: 4.3643162400012026e-05)
Step 42601: (loss: 0.08138584345579147, loss_fm: 0.0736161321401596, loss_sc: 0.007769712246954441, lr: 4.360165755723916e-05)
Step 42701: (loss: 0.07689477503299713, loss_fm: 0.07551927119493484, loss_sc: 0.0013755062827840447, lr: 4.356027090356106e-05)
Step 42801: (loss: 0.06987199187278748, loss_fm: 0.06937704235315323, loss_sc: 0.0004949483554810286, lr: 4.351900187911551e-05)
Step 42901: (loss: 0.07806534320116043, loss_fm: 0.07738911360502243, loss_sc: 0.0006762283737771213, lr: 4.347784992774615e-05)
Step 43001: (loss: 0.07511483877897263, loss_fm: 0.07230649888515472, loss_sc: 0.002808336867019534, lr: 4.343681449697101e-05)
Step 43101: (loss: 0.07477226853370667, loss_fm: 0.07408808916807175, loss_sc: 0.0006841816939413548, lr: 4.339589503795138e-05)
Step 43201: (loss: 0.0709846243262291, loss_fm: 0.06943129748106003, loss_sc: 0.0015533280093222857, lr: 4.3355091005460974e-05)
Step 43301: (loss: 0.07186082005500793, loss_fm: 0.07016025483608246, loss_sc: 0.0017005689442157745, lr: 4.331440185785537e-05)
Step 43401: (loss: 0.07738251984119415, loss_fm: 0.07530970871448517, loss_sc: 0.002072814153507352, lr: 4.327382705704187e-05)
Step 43501: (loss: 0.08059690147638321, loss_fm: 0.07907643169164658, loss_sc: 0.0015204697847366333, lr: 4.3233366068449585e-05)
Step 43601: (loss: 0.0802496001124382, loss_fm: 0.07870864868164062, loss_sc: 0.001540954690426588, lr: 4.319301836099988e-05)
Step 43701: (loss: 0.07486020028591156, loss_fm: 0.07355699688196182, loss_sc: 0.0013032053830102086, lr: 4.315278340707706e-05)
Step 43801: (loss: 0.07839717715978622, loss_fm: 0.07664470374584198, loss_sc: 0.001752474345266819, lr: 4.311266068249939e-05)
Step 43901: (loss: 0.07339878380298615, loss_fm: 0.07295042276382446, loss_sc: 0.000448363833129406, lr: 4.307264966649046e-05)
Step 44001: (loss: 0.07860254496335983, loss_fm: 0.07809443026781082, loss_sc: 0.0005081127746962011, lr: 4.3032749841650764e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 44101: (loss: 0.07156313210725784, loss_fm: 0.06913000345230103, loss_sc: 0.0024331274908035994, lr: 4.2992960693929584e-05)
Step 44201: (loss: 0.0803089365363121, loss_fm: 0.07901245355606079, loss_sc: 0.0012964803026989102, lr: 4.29532817125972e-05)
Step 44301: (loss: 0.07197166234254837, loss_fm: 0.07179734855890274, loss_sc: 0.00017431408923584968, lr: 4.291371239021733e-05)
Step 44401: (loss: 0.08017906546592712, loss_fm: 0.0752328559756279, loss_sc: 0.004946210887283087, lr: 4.287425222261993e-05)
Step 44501: (loss: 0.0733056366443634, loss_fm: 0.07156186550855637, loss_sc: 0.0017437676433473825, lr: 4.2834900708874134e-05)
Step 44601: (loss: 0.07503858953714371, loss_fm: 0.0729106143116951, loss_sc: 0.0021279763896018267, lr: 4.2795657351261605e-05)
Step 44701: (loss: 0.07214172929525375, loss_fm: 0.06759238243103027, loss_sc: 0.0045493473298847675, lr: 4.275652165525006e-05)
Step 44801: (loss: 0.07394760847091675, loss_fm: 0.07354052364826202, loss_sc: 0.00040708392043597996, lr: 4.2717493129467136e-05)
Step 44901: (loss: 0.07298536598682404, loss_fm: 0.07120709866285324, loss_sc: 0.0017782679060474038, lr: 4.267857128567443e-05)
Step 45001: (loss: 0.07969923317432404, loss_fm: 0.07836507260799408, loss_sc: 0.001334158587269485, lr: 4.263975563874188e-05)
Step 45101: (loss: 0.07988333702087402, loss_fm: 0.0789250060915947, loss_sc: 0.0009583336068317294, lr: 4.2601045706622346e-05)
Step 45201: (loss: 0.07624389231204987, loss_fm: 0.07136201858520508, loss_sc: 0.004881872795522213, lr: 4.2562441010326494e-05)
Step 45301: (loss: 0.06887418031692505, loss_fm: 0.06816328316926956, loss_sc: 0.0007108957506716251, lr: 4.252394107389788e-05)
Step 45401: (loss: 0.07793261110782623, loss_fm: 0.07722266763448715, loss_sc: 0.000709943997208029, lr: 4.24855454243883e-05)
Step 45501: (loss: 0.0742977112531662, loss_fm: 0.07084690779447556, loss_sc: 0.0034508060198277235, lr: 4.244725359183342e-05)
Step 45601: (loss: 0.07714954018592834, loss_fm: 0.07626456022262573, loss_sc: 0.000884980196133256, lr: 4.2409065109228556e-05)
Step 45701: (loss: 0.0779995247721672, loss_fm: 0.07228319346904755, loss_sc: 0.00571632944047451, lr: 4.237097951250484e-05)
Step 45801: (loss: 0.07608425617218018, loss_fm: 0.07334260642528534, loss_sc: 0.0027416490484029055, lr: 4.2332996340505454e-05)
Step 45901: (loss: 0.071915403008461, loss_fm: 0.07124368101358414, loss_sc: 0.0006717211799696088, lr: 4.229511513496221e-05)
Step 46001: (loss: 0.07856260985136032, loss_fm: 0.07567509263753891, loss_sc: 0.0028875137213617563, lr: 4.225733544047232e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 46101: (loss: 0.07845047861337662, loss_fm: 0.07591509073972702, loss_sc: 0.002535388106480241, lr: 4.221965680447543e-05)
Step 46201: (loss: 0.07972969114780426, loss_fm: 0.07381316274404526, loss_sc: 0.005916532129049301, lr: 4.218207877723081e-05)
Step 46301: (loss: 0.07723073661327362, loss_fm: 0.07373825460672379, loss_sc: 0.003492478746920824, lr: 4.214460091179484e-05)
Step 46401: (loss: 0.07705066353082657, loss_fm: 0.07399683445692062, loss_sc: 0.0030538293067365885, lr: 4.210722276399864e-05)
Step 46501: (loss: 0.07793694734573364, loss_fm: 0.07731855660676956, loss_sc: 0.0006183891091495752, lr: 4.2069943892426025e-05)
Step 46601: (loss: 0.0809977799654007, loss_fm: 0.07696947455406189, loss_sc: 0.004028305411338806, lr: 4.2032763858391565e-05)
Step 46701: (loss: 0.08406558632850647, loss_fm: 0.07700829207897186, loss_sc: 0.007057296112179756, lr: 4.1995682225918885e-05)
Step 46801: (loss: 0.0766846090555191, loss_fm: 0.07511253654956818, loss_sc: 0.0015720694791525602, lr: 4.195869856171926e-05)
Step 46901: (loss: 0.06896761059761047, loss_fm: 0.06804603338241577, loss_sc: 0.000921579310670495, lr: 4.1921812435170294e-05)
Step 47001: (loss: 0.08293095231056213, loss_fm: 0.08058100938796997, loss_sc: 0.0023499466478824615, lr: 4.1885023418294874e-05)
Step 47101: (loss: 0.07202456891536713, loss_fm: 0.0696898028254509, loss_sc: 0.002334767021238804, lr: 4.184833108574032e-05)
Step 47201: (loss: 0.08037447184324265, loss_fm: 0.07440447807312012, loss_sc: 0.005969994701445103, lr: 4.181173501475775e-05)
Step 47301: (loss: 0.07137002050876617, loss_fm: 0.06996925920248032, loss_sc: 0.0014007631689310074, lr: 4.177523478518157e-05)
Step 47401: (loss: 0.08286015689373016, loss_fm: 0.07913174480199814, loss_sc: 0.0037284099962562323, lr: 4.173882997940927e-05)
Step 47501: (loss: 0.07313869893550873, loss_fm: 0.07108792662620544, loss_sc: 0.002050772774964571, lr: 4.1702520182381315e-05)
Step 47601: (loss: 0.07386042177677155, loss_fm: 0.07043896615505219, loss_sc: 0.003421455854550004, lr: 4.166630498156129e-05)
Step 47701: (loss: 0.06841054558753967, loss_fm: 0.06799598783254623, loss_sc: 0.0004145550192333758, lr: 4.163018396691621e-05)
Step 47801: (loss: 0.08659049868583679, loss_fm: 0.0810329020023346, loss_sc: 0.005557599011808634, lr: 4.159415673089703e-05)
Step 47901: (loss: 0.07765477150678635, loss_fm: 0.07475707679986954, loss_sc: 0.002897692611441016, lr: 4.155822286841931e-05)
Step 48001: (loss: 0.0792190209031105, loss_fm: 0.07738290727138519, loss_sc: 0.0018361122347414494, lr: 4.15223819768441e-05)
	->->-> Saved checkpoints.
	->->-> Sampled.
Step 48101: (loss: 0.06975091248750687, loss_fm: 0.06890183687210083, loss_sc: 0.0008490733453072608, lr: 4.1486633655959005e-05)
Step 48201: (loss: 0.07719813287258148, loss_fm: 0.07675234973430634, loss_sc: 0.0004457865725271404, lr: 4.145097750795938e-05)
Step 48301: (loss: 0.07403994351625443, loss_fm: 0.06815419346094131, loss_sc: 0.005885747727006674, lr: 4.141541313742977e-05)
Step 48401: (loss: 0.07476352900266647, loss_fm: 0.07382380962371826, loss_sc: 0.0009397229296155274, lr: 4.137994015132549e-05)
Step 48501: (loss: 0.0766315832734108, loss_fm: 0.07400334626436234, loss_sc: 0.0026282374747097492, lr: 4.134455815895432e-05)
Step 48601: (loss: 0.07814403623342514, loss_fm: 0.07553192973136902, loss_sc: 0.002612105570733547, lr: 4.1309266771958555e-05)
Step 48701: (loss: 0.08243748545646667, loss_fm: 0.0812356248497963, loss_sc: 0.0012018611887469888, lr: 4.127406560429698e-05)
Step 48801: (loss: 0.07463252544403076, loss_fm: 0.07144883275032043, loss_sc: 0.0031836892012506723, lr: 4.12389542722272e-05)
Step 48901: (loss: 0.07561687380075455, loss_fm: 0.07413599640130997, loss_sc: 0.0014808790292590857, lr: 4.120393239428805e-05)
Step 49001: (loss: 0.07247121632099152, loss_fm: 0.07168202847242355, loss_sc: 0.0007891900022514164, lr: 4.116899959128221e-05)
Step 49101: (loss: 0.07328793406486511, loss_fm: 0.07212039828300476, loss_sc: 0.0011675385758280754, lr: 4.11341554862589e-05)
Step 49201: (loss: 0.07310204952955246, loss_fm: 0.07081582397222519, loss_sc: 0.0022862267214804888, lr: 4.109939970449689e-05)
Step 49301: (loss: 0.08089742809534073, loss_fm: 0.07986785471439362, loss_sc: 0.0010295704705640674, lr: 4.106473187348749e-05)
Step 49401: (loss: 0.07297688722610474, loss_fm: 0.07118861377239227, loss_sc: 0.001788272405974567, lr: 4.1030151622917826e-05)
Step 49501: (loss: 0.07358983159065247, loss_fm: 0.07200972735881805, loss_sc: 0.001580102602019906, lr: 4.0995658584654215e-05)
Step 49601: (loss: 0.0772094875574112, loss_fm: 0.07286499440670013, loss_sc: 0.004344492685049772, lr: 4.0961252392725714e-05)
Step 49701: (loss: 0.0775536298751831, loss_fm: 0.07285948097705841, loss_sc: 0.004694151226431131, lr: 4.0926932683307764e-05)
Step 49801: (loss: 0.07656947523355484, loss_fm: 0.07569475471973419, loss_sc: 0.0008747185347601771, lr: 4.089269909470613e-05)
Step 49901: (loss: 0.07366956770420074, loss_fm: 0.07335752993822098, loss_sc: 0.00031203730031847954, lr: 4.085855126734079e-05)
